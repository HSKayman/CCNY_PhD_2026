{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d63fe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.12.0.88-cp37-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (67.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 MB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting numpy\n",
      "  Using cached numpy-2.2.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n",
      "Installing collected packages: numpy, opencv-python\n",
      "Successfully installed numpy-2.2.6 opencv-python-4.12.0.88\n"
     ]
    }
   ],
   "source": [
    "#!pip install opencv-python numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17c4af1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d2054bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_points_1 = [] # Left image points\n",
    "ref_points_2 = [] # Right image points\n",
    "test_mode = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb752be",
   "metadata": {},
   "source": [
    "# ==========================================\n",
    "# PART 1: FUNDAMENTAL MATRIX & EPIPOLES\n",
    "# =========================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d9676b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_points(pts, width, height):\n",
    "    \"\"\"\n",
    "    Normalizes points to improve 8-point algorithm stability.\n",
    "    Translate centroid to origin and scale so average distance is sqrt(2).\n",
    "    \"\"\"\n",
    "    pts = np.array(pts)\n",
    "    centroid = np.mean(pts, axis=0)\n",
    "    \n",
    "    # Shift origin to centroid\n",
    "    shifted_pts = pts - centroid\n",
    "    \n",
    "    # Calculate average distance from origin\n",
    "    mean_dist = np.mean(np.sqrt(np.sum(shifted_pts**2, axis=1)))\n",
    "    \n",
    "    # Scale factor\n",
    "    scale = np.sqrt(2) / mean_dist\n",
    "    \n",
    "    # Construct transformation matrix T\n",
    "    T = np.array([\n",
    "        [scale, 0, -scale * centroid[0]],\n",
    "        [0, scale, -scale * centroid[1]],\n",
    "        [0, 0, 1]\n",
    "    ])\n",
    "    \n",
    "    # Apply T to points (convert to homogeneous coords first)\n",
    "    pts_h = np.column_stack((pts, np.ones(len(pts))))\n",
    "    pts_norm = (T @ pts_h.T).T\n",
    "    \n",
    "    return pts_norm[:, :2], T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4206c85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_fundamental_matrix(pts1, pts2):\n",
    "    \"\"\"\n",
    "    Computes F using the normalized 8-point algorithm.\n",
    "    Reference: Stereo Vision Slides, Page 32.\n",
    "    \"\"\"\n",
    "    h, w = 1000, 1000 # Arbitrary for normalization, just need image dims\n",
    "    \n",
    "    # 1. Normalize points\n",
    "    pts1_norm, T1 = normalize_points(pts1, w, h)\n",
    "    pts2_norm, T2 = normalize_points(pts2, w, h)\n",
    "    \n",
    "    # 2. Build Constraint Matrix A\n",
    "    # Equation: p2' * F * p1 = 0 -> [u'u, u'v, u', v'u, v'v, v', u, v, 1] * f = 0\n",
    "    A = []\n",
    "    for i in range(len(pts1)):\n",
    "        u, v = pts1_norm[i]\n",
    "        u_p, v_p = pts2_norm[i]\n",
    "        A.append([u_p*u, u_p*v, u_p, v_p*u, v_p*v, v_p, u, v, 1])\n",
    "    A = np.array(A)\n",
    "    \n",
    "    # 3. SVD of A to find F\n",
    "    U, S, Vt = np.linalg.svd(A)\n",
    "    F_prime = Vt[-1].reshape(3, 3)\n",
    "    \n",
    "    # 4. Enforce Rank 2 Constraint (Singularity constraint)\n",
    "    # Reference: Stereo Vision Slides, Page 32 (\"Set smallest singular value to 0\")\n",
    "    Uf, Sf, Vtf = np.linalg.svd(F_prime)\n",
    "    Sf[2] = 0 # Zero out smallest singular value\n",
    "    F_rank2 = Uf @ np.diag(Sf) @ Vtf\n",
    "    \n",
    "    # 5. De-normalize: F = T2' * F_rank2 * T1\n",
    "    F = T2.T @ F_rank2 @ T1\n",
    "    \n",
    "    # Normalize F so last element is 1 (standard convention)\n",
    "    return F / F[2, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1689d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_epipoles(F):\n",
    "    \"\"\"\n",
    "    Computes epipoles using SVD.\n",
    "    Reference: Stereo Vision Slides, Page 33.\n",
    "    \"\"\"\n",
    "    # Epipole e1 (left) is null space of F: F * e1 = 0\n",
    "    U, S, Vt = np.linalg.svd(F)\n",
    "    e1 = Vt[-1]\n",
    "    e1 = e1 / e1[2] # Normalize\n",
    "    \n",
    "    # Epipole e2 (right) is null space of F.T: F.T * e2 = 0\n",
    "    U, S, Vt = np.linalg.svd(F.T)\n",
    "    e2 = Vt[-1]\n",
    "    e2 = e2 / e2[2] # Normalize\n",
    "    \n",
    "    return e1, e2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5af2e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_epipolar_line(pt, F, which_image):\n",
    "    \"\"\"\n",
    "    Computes the line equation ax + by + c = 0.\n",
    "    If pt is in image 1, line is in image 2: l' = F * p\n",
    "    If pt is in image 2, line is in image 1: l = F.T * p'\n",
    "    \"\"\"\n",
    "    pt_h = np.array([pt[0], pt[1], 1])\n",
    "    \n",
    "    if which_image == 1: # Point in Img1, line in Img2\n",
    "        line = F @ pt_h\n",
    "    else: # Point in Img2, line in Img1\n",
    "        line = F.T @ pt_h\n",
    "        \n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1028dc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_distance_to_line(pt, line):\n",
    "    \"\"\" Calculates geometric distance from point (x,y) to line ax+by+c=0 \"\"\"\n",
    "    a, b, c = line\n",
    "    x, y = pt\n",
    "    return abs(a*x + b*y + c) / math.sqrt(a**2 + b**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f41217",
   "metadata": {},
   "source": [
    "# ==========================================\n",
    "# PART 2: FEATURE MATCHING & GUI\n",
    "# =========================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "696e5c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_feature_along_line(img1, img2, pt_clicked, F, window_size=15):\n",
    "    \"\"\"\n",
    "    Searches for the corresponding point in img2 along the epipolar line.\n",
    "    Uses Sum of Squared Differences (SSD).\n",
    "    Reference: \"Correspondence Problem\", Slides 41-45.\n",
    "    \"\"\"\n",
    "    h, w, _ = img2.shape\n",
    "    \n",
    "    # 1. Get Epipolar Line in Image 2\n",
    "    line = compute_epipolar_line(pt_clicked, F, 1) # a*x + b*y + c = 0\n",
    "    a, b, c = line\n",
    "    \n",
    "    # 2. Extract template from Image 1\n",
    "    x, y = pt_clicked\n",
    "    half_w = window_size // 2\n",
    "    \n",
    "    # Check bounds\n",
    "    if x < half_w or x >= w - half_w or y < half_w or y >= h - half_w:\n",
    "        print(\"Point too close to border.\")\n",
    "        return None\n",
    "\n",
    "    template = img1[y-half_w:y+half_w+1, x-half_w:x+half_w+1].astype(np.float32)\n",
    "    \n",
    "    # 3. Scan along the epipolar line in Image 2\n",
    "    best_score = float('inf')\n",
    "    best_pt = None\n",
    "    \n",
    "    # We iterate x from 0 to width (assuming line isn't vertical)\n",
    "    # Ideally we should trace the line pixels properly (Bresenham or similar)\n",
    "    # Simple approximation: calculate y for every x\n",
    "    \n",
    "    for x2 in range(half_w, w - half_w):\n",
    "        # Calculate y on the line: y = (-c - ax) / b\n",
    "        if abs(b) > 1e-5:\n",
    "            y2 = int((-c - a * x2) / b)\n",
    "        else:\n",
    "            continue # Vertical line handling skipped for brevity\n",
    "            \n",
    "        if y2 < half_w or y2 >= h - half_w:\n",
    "            continue\n",
    "            \n",
    "        # Extract window in Image 2\n",
    "        patch = img2[y2-half_w:y2+half_w+1, x2-half_w:x2+half_w+1].astype(np.float32)\n",
    "        \n",
    "        # Compute SSD (Sum of Squared Differences)\n",
    "        score = np.sum((template - patch)**2)\n",
    "        \n",
    "        if score < best_score:\n",
    "            best_score = score\n",
    "            best_pt = (x2, y2)\n",
    "            \n",
    "    return best_pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d23f1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mouse_callback(event, x, y, flags, param):\n",
    "    global ref_points_1, ref_points_2, test_mode, F_matrix, img1, img2_display\n",
    "    \n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        if not test_mode:\n",
    "            # Calibration Phase: Collect pairs\n",
    "            if len(ref_points_1) == len(ref_points_2):\n",
    "                ref_points_1.append((x, y))\n",
    "                print(f\"Point {len(ref_points_1)} on Left Image recorded: ({x},{y}). Click corresponding point on Right.\")\n",
    "                cv2.circle(img_combined, (x, y), 5, (0, 0, 255), -1)\n",
    "            else:\n",
    "                # Adjust x for the right image (displayed side-by-side)\n",
    "                real_x = x - img1.shape[1] \n",
    "                if real_x < 0:\n",
    "                    print(\"Please click on the Right image.\")\n",
    "                    return\n",
    "                ref_points_2.append((real_x, y))\n",
    "                print(f\"Point {len(ref_points_2)} on Right Image recorded: ({real_x},{y}).\")\n",
    "                cv2.circle(img_combined, (x, y), 5, (0, 255, 0), -1)\n",
    "                \n",
    "                if len(ref_points_1) == 8:\n",
    "                    print(\"--- 8 Points collected. Press 'c' to Compute F or click more for better accuracy ---\")\n",
    "\n",
    "            cv2.imshow(\"Stereo Lab\", img_combined)\n",
    "            \n",
    "        else:\n",
    "            # Testing Phase: Feature Matching\n",
    "            if x < img1.shape[1]: # Clicked on Left Image\n",
    "                print(f\"\\nSearching match for ({x}, {y})...\")\n",
    "                \n",
    "                # Draw point on left\n",
    "                img_show = img_combined.copy()\n",
    "                cv2.circle(img_show, (x, y), 5, (255, 0, 0), -1)\n",
    "                \n",
    "                # Find match\n",
    "                match_pt = match_feature_along_line(img1, img2, (x,y), F_matrix)\n",
    "                \n",
    "                if match_pt:\n",
    "                    print(f\"Match found at: {match_pt}\")\n",
    "                    \n",
    "                    # Draw Epipolar Line on Right Image\n",
    "                    # line: ax + by + c = 0\n",
    "                    line = compute_epipolar_line((x,y), F_matrix, 1)\n",
    "                    x0, y0 = 0, int(-line[2]/line[1])\n",
    "                    x1, y1 = img2.shape[1], int(-(line[2] + line[0]*img2.shape[1])/line[1])\n",
    "                    \n",
    "                    # Offset for visualization (right image starts at w)\n",
    "                    w = img1.shape[1]\n",
    "                    cv2.line(img_show, (x0 + w, y0), (x1 + w, y1), (0, 255, 255), 1)\n",
    "                    \n",
    "                    # Draw Crosshair on match\n",
    "                    mx, my = match_pt\n",
    "                    mx += w # Offset\n",
    "                    cv2.drawMarker(img_show, (mx, my), (0, 255, 0), cv2.MARKER_CROSS, 20, 2)\n",
    "                    \n",
    "                    cv2.imshow(\"Stereo Lab\", img_show)\n",
    "                else:\n",
    "                    print(\"Match not found (out of bounds).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370ce89a",
   "metadata": {},
   "source": [
    "# ==========================================\n",
    "# MAIN\n",
    "# =========================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7cc4274b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pic410.png and pic430.jpg...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "global img1, img2, img_combined, test_mode, F_matrix\n",
    "\n",
    "# Load Images\n",
    "print(\"Loading pic410.png and pic430.jpg...\")\n",
    "img1 = cv2.imread('./pic410.png')\n",
    "img2 = cv2.imread('./pic430.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd649d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resize for easier viewing if too large\n",
    "img1 = cv2.resize(img1, (0,0), fx=0.5, fy=0.5)\n",
    "img2 = cv2.resize(img2, (0,0), fx=0.5, fy=0.5)\n",
    "\n",
    "# Create side-by-side view\n",
    "img_combined = np.hstack((img1, img2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c921302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================\n",
      "PART 1: Manual Calibration\n",
      "1. Click a point on the LEFT image.\n",
      "2. Click the corresponding point on the RIGHT image.\n",
      "3. Repeat at least 8 times (10-12 recommended).\n",
      "4. Press 'c' to calculate Fundamental Matrix.\n",
      "=======================================================\n",
      "Point 1 on Right Image recorded: (106,207).\n",
      "Point 2 on Left Image recorded: (151,191). Click corresponding point on Right.\n",
      "Point 2 on Right Image recorded: (109,203).\n",
      "Point 3 on Left Image recorded: (188,249). Click corresponding point on Right.\n",
      "Point 3 on Right Image recorded: (149,271).\n",
      "Point 4 on Left Image recorded: (52,153). Click corresponding point on Right.\n",
      "Point 4 on Right Image recorded: (7,170).\n",
      "Point 5 on Left Image recorded: (283,216). Click corresponding point on Right.\n",
      "Point 5 on Right Image recorded: (151,201).\n",
      "Point 6 on Left Image recorded: (385,248). Click corresponding point on Right.\n",
      "Point 6 on Right Image recorded: (148,280).\n",
      "Point 7 on Left Image recorded: (387,342). Click corresponding point on Right.\n",
      "Point 7 on Right Image recorded: (15,297).\n",
      "Point 8 on Left Image recorded: (203,278). Click corresponding point on Right.\n",
      "Please click on the Right image.\n",
      "Please click on the Right image.\n",
      "Please click on the Right image.\n",
      "Please click on the Right image.\n",
      "Please click on the Right image.\n",
      "Please click on the Right image.\n",
      "Point 8 on Right Image recorded: (39,188).\n",
      "--- 8 Points collected. Press 'c' to Compute F or click more for better accuracy ---\n",
      "Point 9 on Left Image recorded: (289,198). Click corresponding point on Right.\n",
      "Point 9 on Right Image recorded: (68,228).\n",
      "Point 10 on Left Image recorded: (321,251). Click corresponding point on Right.\n",
      "Point 10 on Right Image recorded: (90,260).\n",
      "Point 11 on Left Image recorded: (349,272). Click corresponding point on Right.\n",
      "Point 11 on Right Image recorded: (136,258).\n",
      "Point 12 on Left Image recorded: (396,233). Click corresponding point on Right.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStereo Lab\u001b[39m\u001b[38;5;124m\"\u001b[39m, img_combined)\n\u001b[0;32m---> 15\u001b[0m     key \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwaitKey\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;241m&\u001b[39m \u001b[38;5;241m0xFF\u001b[39m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mq\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     18\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "cv2.namedWindow(\"Stereo Lab\")\n",
    "cv2.setMouseCallback(\"Stereo Lab\", mouse_callback)\n",
    "\n",
    "print(\"=======================================================\")\n",
    "print(\"PART 1: Manual Calibration\")\n",
    "print(\"1. Click a point on the LEFT image.\")\n",
    "print(\"2. Click the corresponding point on the RIGHT image.\")\n",
    "print(\"3. Repeat at least 8 times (10-12 recommended).\")\n",
    "print(\"4. Press 'c' to calculate Fundamental Matrix.\")\n",
    "print(\"=======================================================\")\n",
    "\n",
    "\n",
    "while True:\n",
    "    cv2.imshow(\"Stereo Lab\", img_combined)\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    \n",
    "    if key == ord('q'):\n",
    "        break\n",
    "        \n",
    "    elif key == ord('c') and len(ref_points_1) >= 8:\n",
    "        # Separate Control Points (first 8) and Test Points (rest)\n",
    "        ctrl_p1 = ref_points_1[:8]\n",
    "        ctrl_p2 = ref_points_2[:8]\n",
    "        \n",
    "        test_p1 = ref_points_1[8:]\n",
    "        test_p2 = ref_points_2[8:]\n",
    "        \n",
    "        print(f\"\\nComputing F using {len(ctrl_p1)} control points...\")\n",
    "        F_matrix = compute_fundamental_matrix(ctrl_p1, ctrl_p2)\n",
    "        \n",
    "        print(\"\\nFundamental Matrix F:\")\n",
    "        print(F_matrix)\n",
    "        \n",
    "        e1, e2 = compute_epipoles(F_matrix)\n",
    "        print(f\"\\nEpipole Left: {e1}\")\n",
    "        print(f\"Epipole Right: {e2}\")\n",
    "        \n",
    "        # Check Accuracy\n",
    "        total_err = 0\n",
    "        if len(test_p1) > 0:\n",
    "            print(\"\\nAccuracy Check (Distance to Epipolar Line):\")\n",
    "            for i in range(len(test_p1)):\n",
    "                # Line in right image for point in left\n",
    "                l2 = compute_epipolar_line(test_p1[i], F_matrix, 1)\n",
    "                dist = calculate_distance_to_line(test_p2[i], l2)\n",
    "                total_err += dist\n",
    "                print(f\"Test Point {i+1}: Distance = {dist:.4f} pixels\")\n",
    "            print(f\"Average Error: {total_err/len(test_p1):.4f} pixels\")\n",
    "        else:\n",
    "            print(\"\\nNo extra points clicked for testing. (Click more than 8 next time!)\")\n",
    "            \n",
    "        print(\"\\n=======================================================\")\n",
    "        print(\"PART 2: Feature Matching\")\n",
    "        print(\"Click anywhere on the LEFT image to find its match in the RIGHT.\")\n",
    "        print(\"The search is constrained along the epipolar line.\")\n",
    "        print(\"Press 'q' to quit.\")\n",
    "        print(\"=======================================================\")\n",
    "        test_mode = True\n",
    "        \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0264b86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".forcv (3.10.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
