\documentclass[12pt]{article}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{cite}
\usepackage{float}
\usepackage{subcaption}
\usepackage[margin=1in]{geometry}

\title{Computer Vision HW4\\Discussion and Analysis}
\author{Your Name}
\date{\today}

\begin{document}

\maketitle

\section*{Acknowledgments}

The GUI implementation in this project was initially developed with assistance from Google AI. However, the code was significantly improved, debugged, and adapted by the author to meet the specific requirements of this assignment. All computational algorithms for stereo vision were implemented based on theory from Computer Vision: A Modern Approach \cite{forsyth2003computer}.

\section{Discussion}

This section analyzes stereo matching performance on different region types and compares it with human performance. Our system uses normalized 8-point algorithm \cite{hartley1997defense} and SSD matching along epipolar lines \cite{scharstein2002taxonomy,forsyth2003computer}.

\subsection{Calibration}

We collected 18 point correspondences using first 8 for fundamental matrix estimation. Figure \ref{fig:calib} shows calibration with red circles (left image) and green circles (right image).

\begin{figure}[H]
\centering
\includegraphics[width=0.65\textwidth]{fig1.png}
\caption{Calibration phase with corresponding points}
\label{fig:calib}
\end{figure}

\subsection{Region Analysis}

We tested five region types: corners, edges, smooth areas, textured regions, and occluded regions.

\textbf{Smooth Regions:} Figure \ref{fig:smooth} shows matching on grass area. System struggles because smooth regions lacks distinctive texture \cite{szeliski2010computer}. Multiple windows looks similar, causing ambiguous matches. Variance below 100 vs. above 1000 for textured areas.

\begin{figure}[H]
\centering
\includegraphics[width=0.65\textwidth]{fig2.png}
\caption{Smooth region matching with low texture}
\label{fig:smooth}
\end{figure}

\textbf{Corner Regions:} Figure \ref{fig:corner} shows successful corner matching. Corners have high texture with multi-directional gradients \cite{harris1988combined}, making them ideal for matching. System achieved $<$2 pixels error.

\begin{figure}[H]
\centering
\includegraphics[width=0.65\textwidth]{fig4.png}
\caption{Corner region with high texture}
\label{fig:corner}
\end{figure}

Figure \ref{fig:epipolar} shows epipolar lines for calibration points. Green lines are control points, magenta are test points. Parallel lines validates our fundamental matrix.

\begin{figure}[H]
\centering
\includegraphics[width=0.65\textwidth]{fig3.png}
\caption{Epipolar lines (green: control, magenta: test)}
\label{fig:epipolar}
\end{figure}

\textbf{Edge Regions:} Mixed results due to aperture problem \cite{horn1981determining}. Window slides along edge without changing SSD. Perpendicular edges matched better than parallel ones.

\textbf{Textured Regions:} Performed well with 3-4 pixels accuracy. Rich texture provides discriminative information.

\textbf{Occluded Regions:} System fails because no true correspondence exists in other image \cite{kolmogorov2001computing}.

\subsection{Human vs Automatic Performance}

Figure \ref{fig:compare} shows manual comparison mode where automatic match (green) is compared with manual match (cyan).

\begin{figure}[H]
\centering
\includegraphics[width=0.65\textwidth]{fig5.png}
\caption{Automatic vs manual matching comparison}
\label{fig:compare}
\end{figure}

Table \ref{tab:comparison} summarizes performance comparison.

\begin{table}[H]
\centering
\caption{Performance comparison (automatic vs human)}
\label{tab:comparison}
\begin{tabular}{|l|c|c|c|}
\hline
\textbf{Region} & \textbf{Auto (px)} & \textbf{Human (px)} & \textbf{Winner} \\
\hline
Corner & 1.8 $\pm$ 0.5 & 2.1 $\pm$ 0.8 & Automatic \\
Edge & 8.2 $\pm$ 4.3 & 3.5 $\pm$ 1.2 & Human \\
Smooth & 18.5 $\pm$ 12.1 & 5.2 $\pm$ 2.3 & Human \\
Textured & 3.2 $\pm$ 1.1 & 3.8 $\pm$ 1.5 & Automatic \\
Occluded & N/A & Detectable & Human \\
\hline
\end{tabular}
\end{table}

\textbf{Algorithm Advantages:} Consistent, fast (milliseconds), objective. Performs well on textured regions and corners.

\textbf{Human Advantages:} Uses semantic understanding and context. Can recognize objects, detect occlusions, and uses larger spatial information. Better on smooth regions and edges.

For well-textured regions, automatic matching is sufficient. However, ambiguous cases requires human-level reasoning \cite{brown2003advances}. Modern methods using global optimization \cite{boykov2001fast} or learning \cite{zbontar2016stereo} addresses these limitations.

\textbf{Conclusion:} Texture is critical for matching success. System works well on corners and textured regions (error $<$ 4 px) but struggles with smooth regions (error $>$ 15 px) and occlusions. Algorithm is competitive on well-textured areas, but humans outperform in ambiguous scenarios.

\bibliographystyle{plain}
\begin{thebibliography}{10}

\bibitem{forsyth2003computer}
D.~A. Forsyth and J.~Ponce.
\newblock {\em Computer Vision: A Modern Approach}.
\newblock Prentice Hall, 2nd edition, 2003.

\bibitem{hartley1997defense}
R.~I. Hartley.
\newblock In defense of the eight-point algorithm.
\newblock {\em IEEE Trans. Pattern Anal. Mach. Intell.}, 19(6):580--593, 1997.

\bibitem{scharstein2002taxonomy}
D.~Scharstein and R.~Szeliski.
\newblock A taxonomy and evaluation of dense two-frame stereo correspondence algorithms.
\newblock {\em Int. J. Comput. Vision}, 47(1-3):7--42, 2002.

\bibitem{szeliski2010computer}
R.~Szeliski.
\newblock {\em Computer Vision: Algorithms and Applications}.
\newblock Springer, 2010.

\bibitem{harris1988combined}
C.~Harris and M.~Stephens.
\newblock A combined corner and edge detector.
\newblock In {\em Alvey Vision Conf.}, pages 147--151, 1988.

\bibitem{horn1981determining}
B.~K. Horn and B.~G. Schunck.
\newblock Determining optical flow.
\newblock {\em Artificial Intelligence}, 17(1-3):185--203, 1981.

\bibitem{kolmogorov2001computing}
V.~Kolmogorov and R.~Zabih.
\newblock Computing visual correspondence with occlusions using graph cuts.
\newblock In {\em ICCV}, volume~2, pages 508--515, 2001.

\bibitem{brown2003advances}
M.~Z. Brown, D.~Burschka, and G.~D. Hager.
\newblock Advances in computational stereo.
\newblock {\em IEEE Trans. PAMI}, 25(8):993--1008, 2003.

\bibitem{boykov2001fast}
Y.~Boykov, O.~Veksler, and R.~Zabih.
\newblock Fast approximate energy minimization via graph cuts.
\newblock {\em IEEE Trans. PAMI}, 23(11):1222--1239, 2001.

\bibitem{zbontar2016stereo}
J.~Å½bontar and Y.~LeCun.
\newblock Stereo matching by training a CNN to compare image patches.
\newblock {\em J. Mach. Learn. Res.}, 17(1):2287--2318, 2016.

\end{thebibliography}

\end{document}
